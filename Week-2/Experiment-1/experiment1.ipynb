{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CSET419 – Introduction to Generative AI\n",
        "## Lab 2 – Experiment 1\n",
        "### Training a Basic GAN for MNIST Image Generation\n",
        "\n",
        "**Objective:**  \n",
        "To design and train a Generative Adversarial Network (GAN) to generate synthetic handwritten digit images using the MNIST dataset and evaluate their quality.\n",
        "\n",
        "**Platform:** Google Colab  \n",
        "**Framework:** PyTorch\n"
      ],
      "metadata": {
        "id": "QG2xU7dw8R_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Import Required Libraries\n"
      ],
      "metadata": {
        "id": "81_-8mja8ZQE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "w9y5eiI2pfuV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7peiqBMqc4d",
        "outputId": "de6f300c-7eb0-4a03-fe7f-6d4a8b3007be"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Set Device and Input Parameters\n"
      ],
      "metadata": {
        "id": "sAaCug608f_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== User Inputs =====\n",
        "dataset_choice = 'mnist'   # only mnist for now\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "noise_dim = 100\n",
        "learning_rate = 0.0002\n",
        "save_interval = 5\n"
      ],
      "metadata": {
        "id": "xwNnYR1UpqlN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Load and Preprocess MNIST Dataset\n"
      ],
      "metadata": {
        "id": "IAPhXyMU8qCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "dataset = datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "zlDFJIe8pqfc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Define the Discriminator Network\n"
      ],
      "metadata": {
        "id": "h1_TXMQF8tYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        validity = self.model(img_flat)\n",
        "        return validity\n"
      ],
      "metadata": {
        "id": "F6l3kfi4sfa6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = Discriminator().to(device)\n"
      ],
      "metadata": {
        "id": "YSrubHt3yup_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Define the Generator Network\n"
      ],
      "metadata": {
        "id": "LzjroufD8y8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(noise_dim, 256),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(1024, 28 * 28),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img_flat = self.model(z)\n",
        "        img = img_flat.view(z.size(0), 1, 28, 28)\n",
        "        return img\n"
      ],
      "metadata": {
        "id": "g5I4V35wpqdJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator().to(device)\n"
      ],
      "metadata": {
        "id": "MQeDKoBvypAi"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Define Loss Function and Optimizers\n"
      ],
      "metadata": {
        "id": "TZuX2oAR83xK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_loss = nn.BCELoss()\n"
      ],
      "metadata": {
        "id": "P2ClF6CRxT9m"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "ELUZA2iOx7B1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_label = 1.0\n",
        "fake_label = 0.0\n"
      ],
      "metadata": {
        "id": "ME0R20aDyysB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Train the GAN Model\n"
      ],
      "metadata": {
        "id": "PS-2C2mI87v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"generated_samples\", exist_ok=True)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    for i, (real_images, _) in enumerate(dataloader):\n",
        "\n",
        "        batch_size_curr = real_images.size(0)\n",
        "\n",
        "        # ======================\n",
        "        #  Train Discriminator\n",
        "        # ======================\n",
        "        discriminator.zero_grad()\n",
        "\n",
        "        # Real images\n",
        "        real_images = real_images.to(device)\n",
        "        real_targets = torch.full((batch_size_curr, 1), real_label, device=device)\n",
        "\n",
        "        real_output = discriminator(real_images)\n",
        "        d_loss_real = adversarial_loss(real_output, real_targets)\n",
        "\n",
        "        # Fake images\n",
        "        noise = torch.randn(batch_size_curr, noise_dim, device=device)\n",
        "        fake_images = generator(noise)\n",
        "\n",
        "        fake_targets = torch.full((batch_size_curr, 1), fake_label, device=device)\n",
        "        fake_output = discriminator(fake_images.detach())\n",
        "        d_loss_fake = adversarial_loss(fake_output, fake_targets)\n",
        "\n",
        "        # Total Discriminator loss\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # ======================\n",
        "        #  Train Generator\n",
        "        # ======================\n",
        "        generator.zero_grad()\n",
        "\n",
        "        fake_targets = torch.full((batch_size_curr, 1), real_label, device=device)\n",
        "        output = discriminator(fake_images)\n",
        "        g_loss = adversarial_loss(output, fake_targets)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    # ======================\n",
        "    # Logging\n",
        "    # ======================\n",
        "    print(f\"Epoch {epoch}/{epochs} | D_loss: {d_loss.item():.4f} | G_loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    # ======================\n",
        "    # Save Images\n",
        "    # ======================\n",
        "    if epoch % save_interval == 0:\n",
        "        save_image(fake_images[:25], f\"generated_samples/epoch_{epoch:02d}.png\",\n",
        "                   nrow=5, normalize=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xJqy8b9y_6a",
        "outputId": "842a7759-b983-4e23-b5d9-4169bb60b158"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 | D_loss: 0.0195 | G_loss: 5.7767\n",
            "Epoch 2/50 | D_loss: 0.7622 | G_loss: 3.1844\n",
            "Epoch 3/50 | D_loss: 1.4343 | G_loss: 2.0612\n",
            "Epoch 4/50 | D_loss: 0.9354 | G_loss: 1.3968\n",
            "Epoch 5/50 | D_loss: 0.7687 | G_loss: 2.2506\n",
            "Epoch 6/50 | D_loss: 0.3121 | G_loss: 4.4063\n",
            "Epoch 7/50 | D_loss: 0.8148 | G_loss: 3.3540\n",
            "Epoch 8/50 | D_loss: 0.3487 | G_loss: 4.3838\n",
            "Epoch 9/50 | D_loss: 0.3353 | G_loss: 4.1856\n",
            "Epoch 10/50 | D_loss: 0.1572 | G_loss: 5.1089\n",
            "Epoch 11/50 | D_loss: 0.1725 | G_loss: 3.5568\n",
            "Epoch 12/50 | D_loss: 0.2362 | G_loss: 4.1887\n",
            "Epoch 13/50 | D_loss: 0.1683 | G_loss: 5.4852\n",
            "Epoch 14/50 | D_loss: 0.1700 | G_loss: 8.8803\n",
            "Epoch 15/50 | D_loss: 0.4032 | G_loss: 3.8065\n",
            "Epoch 16/50 | D_loss: 0.4234 | G_loss: 6.3318\n",
            "Epoch 17/50 | D_loss: 0.3881 | G_loss: 4.5608\n",
            "Epoch 18/50 | D_loss: 0.1293 | G_loss: 5.1988\n",
            "Epoch 19/50 | D_loss: 0.4525 | G_loss: 2.7478\n",
            "Epoch 20/50 | D_loss: 0.7445 | G_loss: 2.4639\n",
            "Epoch 21/50 | D_loss: 1.0109 | G_loss: 3.1016\n",
            "Epoch 22/50 | D_loss: 0.6048 | G_loss: 3.0141\n",
            "Epoch 23/50 | D_loss: 0.6081 | G_loss: 3.2994\n",
            "Epoch 24/50 | D_loss: 0.4432 | G_loss: 2.5553\n",
            "Epoch 25/50 | D_loss: 0.4578 | G_loss: 3.3434\n",
            "Epoch 26/50 | D_loss: 0.8869 | G_loss: 2.4441\n",
            "Epoch 27/50 | D_loss: 0.5341 | G_loss: 3.2138\n",
            "Epoch 28/50 | D_loss: 0.5599 | G_loss: 2.7997\n",
            "Epoch 29/50 | D_loss: 0.7598 | G_loss: 2.6877\n",
            "Epoch 30/50 | D_loss: 0.4074 | G_loss: 2.8189\n",
            "Epoch 31/50 | D_loss: 0.5612 | G_loss: 2.3628\n",
            "Epoch 32/50 | D_loss: 0.6425 | G_loss: 2.4089\n",
            "Epoch 33/50 | D_loss: 0.6362 | G_loss: 2.6636\n",
            "Epoch 34/50 | D_loss: 0.7955 | G_loss: 2.7582\n",
            "Epoch 35/50 | D_loss: 0.6715 | G_loss: 2.3607\n",
            "Epoch 36/50 | D_loss: 1.2945 | G_loss: 1.8561\n",
            "Epoch 37/50 | D_loss: 0.5662 | G_loss: 2.3633\n",
            "Epoch 38/50 | D_loss: 0.7170 | G_loss: 2.9505\n",
            "Epoch 39/50 | D_loss: 0.7205 | G_loss: 2.1851\n",
            "Epoch 40/50 | D_loss: 0.6748 | G_loss: 2.9421\n",
            "Epoch 41/50 | D_loss: 0.8756 | G_loss: 1.8531\n",
            "Epoch 42/50 | D_loss: 0.7032 | G_loss: 1.7732\n",
            "Epoch 43/50 | D_loss: 1.0920 | G_loss: 1.6187\n",
            "Epoch 44/50 | D_loss: 0.6274 | G_loss: 2.0472\n",
            "Epoch 45/50 | D_loss: 0.8058 | G_loss: 2.4266\n",
            "Epoch 46/50 | D_loss: 0.7695 | G_loss: 2.0440\n",
            "Epoch 47/50 | D_loss: 0.6241 | G_loss: 1.8947\n",
            "Epoch 48/50 | D_loss: 1.0690 | G_loss: 1.4903\n",
            "Epoch 49/50 | D_loss: 0.7502 | G_loss: 1.7191\n",
            "Epoch 50/50 | D_loss: 0.7245 | G_loss: 2.0232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8: Generate and Save Final Images\n"
      ],
      "metadata": {
        "id": "39JOLt4c9CE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"final_generated_images\", exist_ok=True)\n",
        "\n",
        "generator.eval()  # evaluation mode\n",
        "\n",
        "with torch.no_grad():\n",
        "    noise = torch.randn(100, noise_dim, device=device)\n",
        "    fake_images = generator(noise)\n",
        "    save_image(fake_images, \"final_generated_images/final_100_images.png\",\n",
        "               nrow=10, normalize=True)\n"
      ],
      "metadata": {
        "id": "lbKxvLj42IL9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST_Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "lLFZrrR03sfZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9: Predict Labels of Generated Images\n"
      ],
      "metadata": {
        "id": "0Nl_mL2v9F7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = MNIST_Classifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_C = optim.Adam(classifier.parameters(), lr=0.001)\n",
        "\n",
        "classifier.train()\n",
        "for epoch in range(3):  # small training\n",
        "    for imgs, labels in dataloader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer_C.zero_grad()\n",
        "        outputs = classifier(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_C.step()\n"
      ],
      "metadata": {
        "id": "dUFKFF073vBG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = classifier(fake_images)\n",
        "    predicted_labels = torch.argmax(outputs, dim=1)\n",
        "\n",
        "# Label distribution\n",
        "labels, counts = torch.unique(predicted_labels, return_counts=True)\n",
        "\n",
        "print(\"Label Distribution of Generated Images:\")\n",
        "for l, c in zip(labels.cpu().numpy(), counts.cpu().numpy()):\n",
        "    print(f\"Digit {l}: {c} images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj_Bk5Tx36po",
        "outputId": "e20561e3-3ba4-44c1-f767-f46228497f44"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Distribution of Generated Images:\n",
            "Digit 0: 3 images\n",
            "Digit 1: 25 images\n",
            "Digit 2: 2 images\n",
            "Digit 3: 10 images\n",
            "Digit 4: 13 images\n",
            "Digit 5: 6 images\n",
            "Digit 6: 10 images\n",
            "Digit 7: 13 images\n",
            "Digit 8: 10 images\n",
            "Digit 9: 8 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results and Observations\n",
        "\n",
        "- The Generator gradually learned to produce realistic handwritten digit images.\n",
        "- Image quality improved over training epochs.\n",
        "- Generated images were saved periodically during training.\n",
        "- A trained MNIST classifier was able to predict meaningful digit labels from the generated images.\n"
      ],
      "metadata": {
        "id": "Z9t5qZg29fvf"
      }
    }
  ]
}