{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CSET419 – Introduction to Generative AI\n",
        "## Lab 2 – Experiment 2\n",
        "### GAN for Fashion-MNIST Image Generation\n",
        "\n",
        "**Objective:**  \n",
        "To train a Generative Adversarial Network (GAN) to generate synthetic Fashion-MNIST clothing images and analyze the generated outputs.\n"
      ],
      "metadata": {
        "id": "n3zjtiAo9B19"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5G_Xi-yG8zQ7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ2vamG29JdL",
        "outputId": "463cebbc-3535-464e-d29e-52d43f67602f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "batch_size = 64\n",
        "noise_dim = 100\n",
        "learning_rate = 0.0002\n",
        "save_interval = 5\n"
      ],
      "metadata": {
        "id": "OTi-pCy29LUu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "dataset = datasets.FashionMNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi32wUku9O_G",
        "outputId": "b27edfb1-d3ee-4f0c-c066-d0068e1166de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.0MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 205kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.80MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 25.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img = img.view(img.size(0), -1)\n",
        "        return self.model(img)\n"
      ],
      "metadata": {
        "id": "zxvpFBDG9RNS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(noise_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 28*28),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        return img.view(z.size(0), 1, 28, 28)\n"
      ],
      "metadata": {
        "id": "C98M5lpN9S-l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n"
      ],
      "metadata": {
        "id": "kGRdJr9D9Uvm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_loss = nn.BCELoss()\n",
        "\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "DGlGpfmq9WmE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"generated_samples\", exist_ok=True)\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    for real_imgs, _ in dataloader:\n",
        "\n",
        "        real_imgs = real_imgs.to(device)\n",
        "        batch_size_curr = real_imgs.size(0)\n",
        "\n",
        "        # Train Discriminator\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        real_labels = torch.ones(batch_size_curr, 1, device=device)\n",
        "        fake_labels = torch.zeros(batch_size_curr, 1, device=device)\n",
        "\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), real_labels)\n",
        "\n",
        "        noise = torch.randn(batch_size_curr, noise_dim, device=device)\n",
        "        fake_imgs = generator(noise)\n",
        "        fake_loss = adversarial_loss(discriminator(fake_imgs.detach()), fake_labels)\n",
        "\n",
        "        d_loss = real_loss + fake_loss\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train Generator\n",
        "        optimizer_G.zero_grad()\n",
        "        g_loss = adversarial_loss(discriminator(fake_imgs), real_labels)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    print(f\"Epoch {epoch}/{epochs} | D_loss: {d_loss.item():.4f} | G_loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    if epoch % save_interval == 0:\n",
        "        save_image(fake_imgs[:25], f\"generated_samples/epoch_{epoch:02d}.png\",\n",
        "                   nrow=5, normalize=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA3rHo8n9Ybi",
        "outputId": "1998f2dc-7628-43af-e5a8-e356335f7d32"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 | D_loss: 0.9319 | G_loss: 2.9195\n",
            "Epoch 2/50 | D_loss: 0.1069 | G_loss: 4.0030\n",
            "Epoch 3/50 | D_loss: 0.0636 | G_loss: 5.0266\n",
            "Epoch 4/50 | D_loss: 0.3880 | G_loss: 3.9242\n",
            "Epoch 5/50 | D_loss: 0.3484 | G_loss: 3.4231\n",
            "Epoch 6/50 | D_loss: 0.4519 | G_loss: 3.7530\n",
            "Epoch 7/50 | D_loss: 0.4149 | G_loss: 1.7600\n",
            "Epoch 8/50 | D_loss: 0.4775 | G_loss: 3.8177\n",
            "Epoch 9/50 | D_loss: 0.5569 | G_loss: 2.9112\n",
            "Epoch 10/50 | D_loss: 0.7102 | G_loss: 2.1881\n",
            "Epoch 11/50 | D_loss: 0.7838 | G_loss: 1.5023\n",
            "Epoch 12/50 | D_loss: 1.2067 | G_loss: 2.3191\n",
            "Epoch 13/50 | D_loss: 0.5225 | G_loss: 2.5338\n",
            "Epoch 14/50 | D_loss: 0.7078 | G_loss: 1.6437\n",
            "Epoch 15/50 | D_loss: 0.9040 | G_loss: 1.8642\n",
            "Epoch 16/50 | D_loss: 1.0668 | G_loss: 1.5264\n",
            "Epoch 17/50 | D_loss: 0.8864 | G_loss: 1.8500\n",
            "Epoch 18/50 | D_loss: 0.8693 | G_loss: 1.6333\n",
            "Epoch 19/50 | D_loss: 1.1876 | G_loss: 1.6648\n",
            "Epoch 20/50 | D_loss: 0.9450 | G_loss: 1.2078\n",
            "Epoch 21/50 | D_loss: 0.8497 | G_loss: 1.3823\n",
            "Epoch 22/50 | D_loss: 0.9162 | G_loss: 1.5333\n",
            "Epoch 23/50 | D_loss: 0.7836 | G_loss: 1.6558\n",
            "Epoch 24/50 | D_loss: 0.8550 | G_loss: 1.6486\n",
            "Epoch 25/50 | D_loss: 1.2204 | G_loss: 1.4910\n",
            "Epoch 26/50 | D_loss: 0.7700 | G_loss: 1.3711\n",
            "Epoch 27/50 | D_loss: 0.8241 | G_loss: 1.4554\n",
            "Epoch 28/50 | D_loss: 1.3339 | G_loss: 1.1647\n",
            "Epoch 29/50 | D_loss: 0.7059 | G_loss: 1.7027\n",
            "Epoch 30/50 | D_loss: 0.9654 | G_loss: 1.4928\n",
            "Epoch 31/50 | D_loss: 1.0283 | G_loss: 1.7283\n",
            "Epoch 32/50 | D_loss: 1.4254 | G_loss: 1.4888\n",
            "Epoch 33/50 | D_loss: 1.6041 | G_loss: 1.3198\n",
            "Epoch 34/50 | D_loss: 0.9732 | G_loss: 1.7723\n",
            "Epoch 35/50 | D_loss: 1.0851 | G_loss: 1.3247\n",
            "Epoch 36/50 | D_loss: 1.1713 | G_loss: 1.7799\n",
            "Epoch 37/50 | D_loss: 1.1661 | G_loss: 1.5954\n",
            "Epoch 38/50 | D_loss: 1.2387 | G_loss: 1.1680\n",
            "Epoch 39/50 | D_loss: 1.2193 | G_loss: 1.0756\n",
            "Epoch 40/50 | D_loss: 0.9212 | G_loss: 1.4662\n",
            "Epoch 41/50 | D_loss: 1.0817 | G_loss: 1.0552\n",
            "Epoch 42/50 | D_loss: 1.3648 | G_loss: 1.5912\n",
            "Epoch 43/50 | D_loss: 1.2688 | G_loss: 1.6341\n",
            "Epoch 44/50 | D_loss: 1.1839 | G_loss: 1.2758\n",
            "Epoch 45/50 | D_loss: 1.3059 | G_loss: 1.2200\n",
            "Epoch 46/50 | D_loss: 0.8428 | G_loss: 1.7597\n",
            "Epoch 47/50 | D_loss: 1.0693 | G_loss: 1.1411\n",
            "Epoch 48/50 | D_loss: 1.2439 | G_loss: 1.6849\n",
            "Epoch 49/50 | D_loss: 1.0442 | G_loss: 1.3441\n",
            "Epoch 50/50 | D_loss: 1.2190 | G_loss: 0.9781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"final_generated_images\", exist_ok=True)\n",
        "\n",
        "generator.eval()\n",
        "with torch.no_grad():\n",
        "    noise = torch.randn(100, noise_dim, device=device)\n",
        "    fake_images = generator(noise)\n",
        "    save_image(fake_images,\n",
        "               \"final_generated_images/final_100_fashion_images.png\",\n",
        "               nrow=10, normalize=True)\n"
      ],
      "metadata": {
        "id": "QD1rHcSI9aXv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results and Observations\n",
        "\n",
        "- The GAN successfully learned Fashion-MNIST image patterns.\n",
        "- Generated images resemble clothing items such as shirts, shoes, and bags.\n",
        "- Compared to MNIST, Fashion-MNIST generation is more complex and less sharp.\n"
      ],
      "metadata": {
        "id": "mVgN_73CDt6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "d-jB7zI3DSr8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = FashionClassifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_C = optim.Adam(classifier.parameters(), lr=0.001)\n",
        "\n",
        "classifier.train()\n",
        "for epoch in range(3):  # small training\n",
        "    for imgs, labels in dataloader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer_C.zero_grad()\n",
        "        outputs = classifier(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_C.step()\n"
      ],
      "metadata": {
        "id": "vneb9_zfDVjQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = classifier(fake_images)\n",
        "    predicted_labels = torch.argmax(outputs, dim=1)\n",
        "\n",
        "labels, counts = torch.unique(predicted_labels, return_counts=True)\n",
        "\n",
        "print(\"Label Distribution of Generated Fashion Images:\")\n",
        "for l, c in zip(labels.cpu().numpy(), counts.cpu().numpy()):\n",
        "    print(f\"Class {l}: {c} images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8nbju5aDbiX",
        "outputId": "5b90a8a2-a888-4d71-b72c-2c1b34710843"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Distribution of Generated Fashion Images:\n",
            "Class 0: 7 images\n",
            "Class 1: 9 images\n",
            "Class 2: 6 images\n",
            "Class 3: 14 images\n",
            "Class 4: 7 images\n",
            "Class 5: 20 images\n",
            "Class 6: 7 images\n",
            "Class 7: 10 images\n",
            "Class 8: 4 images\n",
            "Class 9: 16 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results and Observations\n",
        "\n",
        "- A simple Fashion-MNIST classifier was used to evaluate GAN outputs.\n",
        "- The classifier predicted meaningful clothing categories for generated images.\n",
        "- Compared to MNIST, Fashion-MNIST generation is more complex and visually challenging.\n"
      ],
      "metadata": {
        "id": "gZ_9-7_S9elQ"
      }
    }
  ]
}